{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ziqJyRmnkMLj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "L8jghPP1tcSc"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6yf10f5Nk8TO"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZyaQmG3lrc1w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpe3aO0ykDUm",
    "outputId": "13aa1c70-4332-411b-b571-8133c20e55e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hW6pX6JSpHyj"
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zmvrIQDbs0e3"
   },
   "outputs": [],
   "source": [
    "drive_path = \"/content/drive/MyDrive/Year 4/NLP notebooks and data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "WtvoLSfNjSUj",
    "outputId": "a83dbfd5-6e7a-4996-bc10-baca14f77083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   helpfulVotes           id  \\\n",
      "0           0.0  978474125.0   \n",
      "1           0.0  978053018.0   \n",
      "2           0.0  976992067.0   \n",
      "3           0.0  976690540.0   \n",
      "4           0.0  976664122.0   \n",
      "\n",
      "                                             address     city  \\\n",
      "0  24 Dharmapala Mawatha Dharmapala Mawatha, Colo...  Colombo   \n",
      "1  24 Dharmapala Mawatha Dharmapala Mawatha, Colo...  Colombo   \n",
      "2  24 Dharmapala Mawatha Dharmapala Mawatha, Colo...  Colombo   \n",
      "3  24 Dharmapala Mawatha Dharmapala Mawatha, Colo...  Colombo   \n",
      "4  24 Dharmapala Mawatha Dharmapala Mawatha, Colo...  Colombo   \n",
      "\n",
      "               placeName  numberOfReviews  placeRating  \\\n",
      "0  Nh Collection Colombo             2392          4.5   \n",
      "1  Nh Collection Colombo             2392          4.5   \n",
      "2  Nh Collection Colombo             2392          4.5   \n",
      "3  Nh Collection Colombo             2392          4.5   \n",
      "4  Nh Collection Colombo             2392          4.5   \n",
      "\n",
      "                                              webUrl publishedDate  \\\n",
      "0  https://www.tripadvisor.com/Hotel_Review-g2939...    2024-11-03   \n",
      "1  https://www.tripadvisor.com/Hotel_Review-g2939...    2024-10-30   \n",
      "2  https://www.tripadvisor.com/Hotel_Review-g2939...    2024-10-28   \n",
      "3  https://www.tripadvisor.com/Hotel_Review-g2939...    2024-10-26   \n",
      "4  https://www.tripadvisor.com/Hotel_Review-g2939...    2024-10-26   \n",
      "\n",
      "   userRating  ...  tripType         username  \\\n",
      "0         5.0  ...      SOLO         219nikal   \n",
      "1         1.0  ...  BUSINESS  rajacool1984itz   \n",
      "2         5.0  ...    FAMILY        857navidj   \n",
      "3         5.0  ...    FAMILY      809mickaelt   \n",
      "4         5.0  ...    FAMILY    M1879HRchloet   \n",
      "\n",
      "                                         word_tokens  \\\n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...   \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...   \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...   \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...   \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...   \n",
      "\n",
      "                                          bpe_tokens  \\\n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...   \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...   \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...   \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...   \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...   \n",
      "\n",
      "                                       bigram_tokens  \\\n",
      "0  [('good', 'service'), ('service', 'ayu'), ('ay...   \n",
      "1  [('change', 'r'), ('r', 'lady'), ('lady', 'man...   \n",
      "2  [('perfect', 'liked'), ('liked', 'everything')...   \n",
      "3  [('stay', 'unforgettable'), ('unforgettable', ...   \n",
      "4  [('amazing', 'hotel'), ('hotel', 'well'), ('we...   \n",
      "\n",
      "                                      trigram_tokens  \\\n",
      "0  [('good', 'service', 'ayu'), ('service', 'ayu'...   \n",
      "1  [('change', 'r', 'lady'), ('r', 'lady', 'manag...   \n",
      "2  [('perfect', 'liked', 'everything'), ('liked',...   \n",
      "3  [('stay', 'unforgettable', 'hotel'), ('unforge...   \n",
      "4  [('amazing', 'hotel', 'well'), ('hotel', 'well...   \n",
      "\n",
      "                                   whitespace_tokens  \\\n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...   \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...   \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...   \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...   \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...   \n",
      "\n",
      "                                   rule_based_tokens  \\\n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...   \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...   \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...   \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...   \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...   \n",
      "\n",
      "                                        spacy_tokens  \\\n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...   \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...   \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...   \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...   \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...   \n",
      "\n",
      "                                    wordpiece_tokens  \n",
      "0  ['good', 'service', 'ayu', 'friendly', 'staff'...  \n",
      "1  ['change', 'r', 'lady', 'manager', 'r', 'hotel...  \n",
      "2  ['perfect', 'liked', 'everything', 'staff', 'k...  \n",
      "3  ['stay', 'unforgettable', 'hotel', 'beautiful'...  \n",
      "4  ['amazing', 'hotel', 'well', 'situated', 'colo...  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.csv' with the actual path to your file in Google Drive\n",
    "df = pd.read_csv('/content/drive/MyDrive/Year 4/NLP notebooks and data/dataset_cleaned.csv')\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRQcUnC5m0CK"
   },
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U7J_Q6pjrpS3"
   },
   "outputs": [],
   "source": [
    "text = df['review_text'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y-pbIdbBrnTN"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kpATXUM4r378"
   },
   "outputs": [],
   "source": [
    "# Pad sequences - for training\n",
    "# max_sequence_length = max(len(seq) for seq in sequences)\n",
    "# data = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "bbEN9mb3r61o"
   },
   "outputs": [],
   "source": [
    "# Step 3: Download and Load GloVe Embeddings\n",
    "glove_url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "glove_zip = 'glove.6B.zip'\n",
    "glove_dir = 'glove.6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JtRj1BCsPac",
    "outputId": "d31bfa74-f641-4219-c816-8eefd666024e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GloVe embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Download GloVe embeddings\n",
    "if not os.path.exists(glove_zip):\n",
    "    print(\"Downloading GloVe embeddings...\")\n",
    "    response = requests.get(glove_url)\n",
    "    with open(glove_zip, 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XjEESP2PsAIX"
   },
   "outputs": [],
   "source": [
    "# Extract GloVe embeddings\n",
    "if not os.path.exists(glove_dir):\n",
    "    with zipfile.ZipFile(glove_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(glove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ffnUocBAsXd6"
   },
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "embedding_index = {}\n",
    "embedding_dim = 100  # Using 100-dimensional GloVe vectors\n",
    "glove_file = os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ta2fqAc5tR6p"
   },
   "outputs": [],
   "source": [
    "with open(glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CV8FiTB_tVPf"
   },
   "outputs": [],
   "source": [
    "# Prepare embedding matrix\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PzdvBJYutqR7"
   },
   "outputs": [],
   "source": [
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BDAaW3GOsgR3"
   },
   "outputs": [],
   "source": [
    "# Save the embedding matrix to a file\n",
    "np.save(drive_path+'glove_embedding_matrix.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PZuUSuUesvWj"
   },
   "outputs": [],
   "source": [
    "# Load the embedding matrix from the file\n",
    "embedding_matrix = np.load(drive_path+'glove_embedding_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0inOJc7un6S",
    "outputId": "0227c684-5b7c-444a-caec-4d39a271572a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.024843    0.47766     0.32437    ... -0.22634     0.82833999\n",
      "   0.058472  ]\n",
      " [ 0.43044001 -0.71715999  0.13989    ...  0.082734    1.28840005\n",
      "  -0.019587  ]\n",
      " ...\n",
      " [-0.10628     0.39139     0.43858999 ... -0.94142997 -0.074166\n",
      "   1.27040005]\n",
      " [ 0.12223     0.14296     0.15203001 ...  0.29115999 -0.12074\n",
      "   0.10729   ]\n",
      " [-0.17752001  0.60913998  0.35699001 ... -0.050707    0.18080001\n",
      "   0.40375999]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape #(19401, 100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
